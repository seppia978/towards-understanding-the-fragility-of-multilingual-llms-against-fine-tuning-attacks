_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.10.0
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 55
                - 71
                - 84
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 55
                - 71
                - 84
            "3":
                - 13
                - 15
                - 16
                - 23
                - 55
            "4": 3.10.0
            "5": 0.19.9
            "6": 4.50.3
            "8":
                - 5
            "12": 0.19.9
            "13": linux-x86_64
attn_implementation:
    value: eager
base_model:
    value: meta-llama/Meta-Llama-3.1-8B-Instruct
beta:
    value: 0.1
eval_steps:
    value: 0.1
evaluation_strategy:
    value: steps
gradient_accumulation_steps:
    value: 4
gradient_checkpointing:
    value: true
how_many_samples:
    value: 100
language:
    value: en
learning_rate:
    value: 2e-06
logging_steps:
    value: 1
lr_scheduler_type:
    value: cosine
max_length:
    value: 1024
max_prompt_length:
    value: 512
max_steps:
    value: -1
new_model:
    value: satan-II
num_train_epochs:
    value: 1
optim:
    value: paged_adamw_32bit
output_dir:
    value: /ft-checkpoints/1743678053
per_device_eval_batch_size:
    value: 2
per_device_train_batch_size:
    value: 2
saving_steps:
    value: 1000
torch_dtype:
    value: torch.float16
warmup_steps:
    value: 10
